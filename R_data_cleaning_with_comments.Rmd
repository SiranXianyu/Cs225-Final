---
title: "CS225_data_cleaning"
author: "JialongLi"
date: "11/13/2022"
output: html_document
---
# Data Cleaning and input "Latitude" and "Longitude data" by hand

```{r setup, include=FALSE}
# import necessary packages
library(tidyverse)
library(stringr)
library(readxl)
library(data.table)
```

```{r read data}
# read raw data
data <- read_excel("C:/Users/jialong/Desktop/CS225/mathematician.xls")
data
# select cols that we need
data_select = data |>
  select(Affiliations, `Times Cited, WoS Core`) |>
  drop_na()
```

```{r}
# string split 
After_split = data_select$Affiliations |>
  str_split(";", simplify = TRUE)

Afflication_df = as.data.frame(After_split)
dim(Afflication_df)

data_select$First_author_univ = Afflication_df[,1]

output_1 = data_select |>
  select(First_author_univ, `Times Cited, WoS Core`) |>
  group_by(First_author_univ) |>
  summarise(`Cited_times` = sum(`Times Cited, WoS Core`)) |>
  filter((First_author_univ %like% "University") & First_author_univ != "Arizona State University" & First_author_univ != "Purdue University" & First_author_univ != "Pennsylvania State University" & First_author_univ != "University of North Carolina" & First_author_univ != "Indian Statistical Institute") |>
  arrange(desc(Cited_times))

data_select |>
  filter(First_author_univ == "Harvard University")

output_1$Longitude <- 0.0
output_1$Latitude <- 0.0

output_1

write.csv(output_1, "C:/Users/jialong/Desktop/cs225/data_vertex.csv")

# I think we can keep top 50 or top 100 universities.
# Personally I'll keep top 50. 

# the more the university has more cited_times, the biggest the vertex are on the visualization map.
# in order to keep our map balance (top1 - 70,000; top10 - 10,000; top 50 - 2000), I think it's a good idea to make top 10 universities "sticker", instead of a very very huge vertex, that's ugly and may cause overlapping.
```

```{r}
# remove blocks

# universities in col 1.
head(Afflication_df[,1])
# first is a empty char, remove it!
head(Afflication_df[,2])

# remove first char in the string, because it's empty
Afflication_df[,2] = sub('.', '', Afflication_df[,2])
Afflication_df[,3] = sub('.', '', Afflication_df[,3])
Afflication_df[,4] = sub('.', '', Afflication_df[,4])
Afflication_df[,5] = sub('.', '', Afflication_df[,5])
```

## deduplication
For example, Purdue University System; Purdue University; Purdue University West Lafayette Campus is literally point to one university, but it appears 3 times.
Where we want to remove:

University of Minnesota System
University of Illinois System
University of California System
University System of Georgia
Indiana University System
University System of Maryland
Arizona State University
State University System of Florida
Louisiana State University System
Purdue University System
University of Michigan System
University of Texas System
University of Massachusetts System
University of Nebraska System
University System of Ohio
University of South Carolina System
Indian Institute of Management (IIM System)
Purdue University
Pennsylvania Commonwealth System of Higher Education (PCSHE)
University of Alabama System
Pennsylvania State University
Southern Illinois University System
University of Hawaii System
Texas A&M University System
Louisiana State University System
University of Houston System
University of North Carolina
University of Maine System
University of Alabama System
Auburn University System
Pennsylvania State University
Indian Statistical Institute
University of Tennessee System
University of North Carolina

-> I can do this by regex, but It's more safety to check it by eye first.

```{r}
dim(Afflication_df)
# (606, 19)

# after removing all duplicate universities, there should be 483 rows left.
Afflication_df |>
  select(V1) |>
  filter(!(V1 %like% 'System' | V1 == "Purdue University" | V1 == "Pennsylvania State University" | V1 == "University of North Carolina" | V1 == 'Indian Statistical Institute' | V1 == "University of North Carolina"))

# print to check if the function is correct
for (i in 1:606) {
  if (Afflication_df[i,1] %like% 'System' | Afflication_df[i,1] == "Purdue University" | Afflication_df[i,1] == "Pennsylvania State University" | Afflication_df[i,1] == "University of North Carolina" | Afflication_df[i,1] == "Indian Statistical Institute" | Afflication_df[i,1] == "University of North Carolina" | Afflication_df[i,1] == "Arizona State University") {
    print(Afflication_df[i,1])
  }
}  

# delete them -> overwrite by "" (1 col)
for (i in 1:606) {
  if (Afflication_df[i,1] %like% 'System' | Afflication_df[i,1] == "Purdue University" | Afflication_df[i,1] == "Pennsylvania State University" | Afflication_df[i,1] == "University of North Carolina" | Afflication_df[i,1] == "Indian Statistical Institute" | Afflication_df[i,1] == "University of North Carolina" | Afflication_df[i,1] == "Arizona State University") {
    Afflication_df[i,1] = ""
  }
} 

# delete them -> overwrite by "" (all cols)
for (i in 1:606) {
  for (j in 1:19) {
    if (Afflication_df[i,j] %like% 'System' | Afflication_df[i,j] == "Purdue University" | Afflication_df[i,j] == "Pennsylvania State University" | Afflication_df[i,j] == "University of North Carolina" | Afflication_df[i,j] == "Indian Statistical Institute" | Afflication_df[i,j] == "University of North Carolina" | Afflication_df[i,j] == "Arizona State University") {
    Afflication_df[i,j] = ""
    }
  }
}
```

```{r}
# how many universities left in each layers
Afflication_df |>
  filter(V1 != "") |>
  nrow()
Afflication_df |>
  filter(V2 != "") |>
  nrow()
Afflication_df |>
  filter(V3 != "") |>
  nrow()
Afflication_df |>
  filter(V4 != "") |>
  nrow()
Afflication_df |>
  filter(V5 != "") |>
  nrow()
Afflication_df |>
  filter(V6 != "") |>
  nrow()
Afflication_df |>
  filter(V7 != "") |>
  nrow()
Afflication_df |>
  filter(V8 != "") |>
  nrow()
Afflication_df |>
  filter(V9 != "") |>
  nrow()
Afflication_df |>
  filter(V10 != "") |>
  nrow()
Afflication_df |>
  filter(V11 != "") |>
  nrow()
Afflication_df |>
  filter(V12 != "") |>
  nrow()
Afflication_df |>
  filter(V13 != "") |>
  nrow()
Afflication_df |>
  filter(V14 != "") |>
  nrow()
Afflication_df |>
  filter(V15 != "") |>
  nrow()
Afflication_df |>
  filter(V16 != "") |>
  nrow()
Afflication_df |>
  filter(V17 != "") |>
  nrow()
Afflication_df |>
  filter(V18 != "") |>
  nrow()
Afflication_df |>
  filter(V19 != "") |>
  nrow()
# we' ll only keep papers that have <= 5 writers.
```


```{r}
# transfer the 19 df with features to df with 2 features.
# Which is how the "edge" works.
removed_df = Afflication_df
dim(removed_df)
# push value into result, (1 & 2)
result_1 <- data.frame(matrix(nrow = 7000, ncol = 2))

# 1 & 2
for (i in 1:606) {
  if (removed_df[i,1] != "" & removed_df[i,2] != "")
    result_1$X1[i] = removed_df[i,1]
    result_1$X2[i] = removed_df[i,2]
}

# 1 & 3
for (i in 1:606) {
  if (removed_df[i,1] != "" & removed_df[i,3] != "")
    result_1$X1[i+606] = removed_df[i,1]
    result_1$X2[i+606] = removed_df[i,3]
}

# 1 & 4
for (i in 1:606) {
  if (removed_df[i,1] != "" & removed_df[i,4] != "")
    result_1$X1[i+606*2] = removed_df[i,1]
    result_1$X2[i+606*2] = removed_df[i,4]
}

# 1 & 5
for (i in 1:606) {
  if (removed_df[i,1] != "" & removed_df[i,5] != "")
    result_1$X1[i+606*3] = removed_df[i,1]
    result_1$X2[i+606*3] = removed_df[i,5]
}

# 2 & 3
for (i in 1:606) {
  if (removed_df[i,2] != "" & removed_df[i,3] != "")
    result_1$X1[i+606*4] = removed_df[i,2]
    result_1$X2[i+606*4] = removed_df[i,3]
}

# 2 & 4
for (i in 1:606) {
  if (removed_df[i,2] != "" & removed_df[i,4] != "")
    result_1$X1[i+606*5] = removed_df[i,2]
    result_1$X2[i+606*5] = removed_df[i,4]
}

# 2 & 5
for (i in 1:606) {
  if (removed_df[i,2] != "" & removed_df[i,5] != "")
    result_1$X1[i+606*6] = removed_df[i,2]
    result_1$X2[i+606*6] = removed_df[i,5]
}

# 3 & 4
for (i in 1:606) {
  if (removed_df[i,3] != "" & removed_df[i,4] != "")
    result_1$X1[i+606*7] = removed_df[i,3]
    result_1$X2[i+606*7] = removed_df[i,4]
}

# 3 & 5
for (i in 1:606) {
  if (removed_df[i,3] != "" & removed_df[i,5] != "")
    result_1$X1[i+606*8] = removed_df[i,3]
    result_1$X2[i+606*8] = removed_df[i,5]
}

# 4 & 5
for (i in 1:606) {
  if (removed_df[i,4] != "" & removed_df[i,5] != "")
    result_1$X1[i+606*9] = removed_df[i,4]
    result_1$X2[i+606*9] = removed_df[i,5]
}

# University vs Universidade
# Univ vs College vs Institute
# drop industry organization, like AT&T and NASA
result_drop_non_univ = result_1 |>
  drop_na() |>
  arrange(X1) |>
  filter((X1 %like% "Univ" | X1 %like% "College" | X1 %like% "Institu") & (X2 %like% "Univ" | X2 %like% "College" | X2 %like% "Institu"))

result_drop_non_univ_2 = result_drop_non_univ |>
  filter(!(X1 %like% "Arizona State University" | X2 %like% "Arizona State University"))

result_drop_non_univ_2 |>
  filter(X1 != X2) |>
  rename(Univ_1 = X1, Univ_2 = X2)

result_drop_non_univ_2$Weight =  0.0
write.csv(result_drop_non_univ_2, "C:/Users/jialong/Desktop/cs225/data_edge.csv")
```
